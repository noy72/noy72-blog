---
title: AIコーディングエージェントを使った開発における Tips
description: 設計やタスク分解、デバッグログの活用など、AIコーディングエージェントを使う中で気づいたポイントを簡単にまとめた。
tags: ["AI"]
---

AI コーディングエージェントを使って開発してみた中で、こうすると進めやすいかもと思ったことを整理した。

環境は VSCode + Roo Code + gemini-pro-exp-03-25。
個人開発で、規模の小さい web アプリを新規に開発した。

## 1. 設計とタスク分解を依頼する

いきなり AI にコードを書かせると、思わぬ方向に進んだり、後で大きな手戻りにつながったり、バグって人間が直そうにも差分が大きすぎて大変だったりする。

そうした事態を避けるには、次のような段階を踏むのが効果的だった。

1. **実装したい内容のプランを作成させる**  
   まず、これから実装したい機能について、全体像や設計方針を記述させる。
2. **プランを複数のステップに分解させる**  
   作成されたプランを、より具体的なステップに分割するよう指示する。
3. **ステップごとにサブタスクとして実行させる**  
   分割された各ステップをサブタスクとして取り出し、個別にコード生成などを依頼する。

Roo Code にはタスクの中でさらにタスクを作って進める「サブタスク」の機能があり、ステップごとにサブタスクを作成して進めることができる。「ブーメランタスク」と呼ばれるもので、コンテキストがやたら長くなるのを避けられるし、サブタスクの完了時にコミットすれば差分の大きさもちょうどよくなるので開発の体験は良かった。

この手順を踏むことで、各段階でのアウトプットを確認しながら進められるようになる。もし誤りがあっても、その場で修正しやすくなる。

## 2. デバッグログを出力させる

AI が生成したコードがテストを通らなかったり、想定通りに動かなかったりする場面は少なくない。そういったときに、原因を特定せずに闇雲にコードを修正してハマって抜け出せなくなる場合がある。遺伝的プログラミングするな 😠

このような場当たり的な挙動を抑えるには、デバッグログの出力と確認を指示するのが有効だった。

> 「デバッグログを出力し、その内容を確認したうえで修正方針を決定してください」

みたいなことを伝えてログを追加してもらい、デバッグ時にログを渡すとログの内容から原因を考えてくれる。100% 解決してくれることはないけど、ややマシな挙動をするようになる気がする。

## 3. ドキュメントやルールを更新させる

人間であれば一度覚えた手順や知識を保持できるが、AI コーディングエージェントではそうはいかない。毎回、同じことを説明し直す必要があったりして面倒に感じることが多かった。

そこで、新しい要件が増えたり手順をエージェントの指示したとき、「今の内容をドキュメントに追記して」と指示してドキュメントの情報を増やすようにしていた。こうしておくと、再度説明する代わりに「このドキュメント参考にして」と指示できるようになる。

README を書いても良いし、ルールに追記させるのもよいと思う。自分の場合、

- コミット前に linter, formatter かけて

- コミット前に意味のないコメント消して

といったルールを追記させたりした。

## AI コーディングエージェントを使ってみた感想

使ってみると想像以上にコードをたくさん書いてくれて面白い。今は返事にやや時間がかかるので、空いた時間に別の仕事の指示を AI に出すような、マルチタスク性能が高い人間は活躍しそうだと思った。

とはいえ、まだ任せるのは怖いという印象がある。括弧の不整合というプログラミング初心者みたいなミスをしてハマったり、明らかに不自然なコードを書いて方向修正を指示しないといけなかったり、いくつか人間の介入は必要な画面が見られた。

結局のところ、生成されたコードが正しいか、また期待通りに動作するかを人間が見極めなければいけないため、「技術力」が求められる点は変わらないな〜と思った。AI と同じくらいのアウトプットしかできないと AI に置き換わられそう。

コードレビューまでやってくれたらな〜とは思うが、それが実現するなら実装は全て AI に任せれば良く、いよいよ人間が介入する必要はなくなるので、人間は「ここをやってくれたらな〜」を言い続けることになる気がする。
